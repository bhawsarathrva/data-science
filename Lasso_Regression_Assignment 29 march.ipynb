{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1733f35b",
   "metadata": {},
   "source": [
    "#### Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a497a2a8",
   "metadata": {},
   "source": [
    "Lasso Regression, or Least Absolute Shrinkage and Selection Operator, is a type of linear regression that includes an L1 regularization term. \n",
    "        This regularization adds a penalty equivalent to the absolute value of the coefficients, which helps in shrinking some coefficients to exactly zero, enabling feature selection.\n",
    "\n",
    "**Differences from Other Regression Techniques:**\n",
    "- Lasso differs from Ridge Regression by using L1 regularization instead of L2, which results in sparse models with some coefficients exactly zero.\n",
    "- It performs both regularization and feature selection, unlike OLS which only fits the model without any regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910fcc54",
   "metadata": {},
   "source": [
    "#### Q2. What is the main advantage of using Lasso Regression in feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad242c69",
   "metadata": {},
   "source": [
    "The main advantage of Lasso Regression in feature selection is its ability to shrink irrelevant or less important features' coefficients to exactly zero. \n",
    "        This leads to a sparse model that includes only the most significant predictors, simplifying interpretation and improving computational efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8fadf8",
   "metadata": {},
   "source": [
    "#### Q3. How do you interpret the coefficients of a Lasso Regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267b7f4a",
   "metadata": {},
   "source": [
    "The coefficients of a Lasso Regression model indicate the strength and direction of the relationship between independent variables and the dependent variable. \n",
    "        However, since Lasso applies L1 regularization, some coefficients may be exactly zero, indicating that those features are not important for predicting the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c879e37",
   "metadata": {},
   "source": [
    "#### Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c95bbc",
   "metadata": {},
   "source": [
    "The main tuning parameter in Lasso Regression is the regularization parameter (λ or alpha). \n",
    "        - A higher λ increases the penalty on the coefficients, leading to more coefficients being shrunk to zero (simpler models).\n",
    "        - A lower λ reduces the penalty, resulting in a model closer to OLS regression (more features retained).\n",
    "        Proper tuning of λ is crucial to balance model simplicity and performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f01c3c",
   "metadata": {},
   "source": [
    "#### Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97143cd6",
   "metadata": {},
   "source": [
    "Yes, Lasso Regression can be used for non-linear regression problems by transforming the input features into a non-linear space (e.g., polynomial features or interaction terms). \n",
    "        However, the Lasso model itself remains linear in the transformed feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c96d3e",
   "metadata": {},
   "source": [
    "#### Q6. What is the difference between Ridge Regression and Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6012107d",
   "metadata": {},
   "source": [
    "The key differences between Ridge and Lasso Regression are:\n",
    "1. Regularization Type: Ridge uses L2 regularization (squared coefficients), while Lasso uses L1 regularization (absolute coefficients).\n",
    "2. Coefficient Shrinkage: Ridge shrinks coefficients toward zero but does not eliminate them, while Lasso can shrink some coefficients to exactly zero, enabling feature selection.\n",
    "3. Model Sparsity: Lasso produces sparse models, while Ridge typically retains all features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d3140a",
   "metadata": {},
   "source": [
    "#### Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4e5a38",
   "metadata": {},
   "source": [
    "Yes, Lasso Regression can handle multicollinearity by selecting one feature from a group of highly correlated features and shrinking the others to zero. \n",
    "        This helps in reducing redundancy and improving model interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b59307",
   "metadata": {},
   "source": [
    "#### Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e3738e",
   "metadata": {},
   "source": [
    "The optimal value of λ can be chosen using techniques like:\n",
    "1. **Cross-Validation**: Evaluate the model on different folds of the data and select the λ that minimizes the validation error.\n",
    "2. **Grid Search or Random Search**: Test various values of λ and choose the one with the best performance metrics.\n",
    "3. **Regularization Path**: Visualize how the coefficients change with different λ values and select the one that achieves a balance between simplicity and performance."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
