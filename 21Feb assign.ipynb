{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "Ans. Web scraping is the process of obtaining data from websites. It entails getting information from online pages and preserving it in an organised format, such a database or spreadsheet, so that it may be examined further.\n",
    "\n",
    "There are many uses for web scraping, including:\n",
    "\n",
    "Web scraping can be used to gather information from numerous websites in order to do research and analysis on a certain issue. Researchers wanting to analyse patterns across several sources or firms looking to acquire insight into their rivals may find this useful.\n",
    "\n",
    "\n",
    "Price Monitoring: To make educated pricing decisions, e-commerce businesses frequently employ web scraping to track the cost of goods offered by their rivals. This aids companies in maintaining competition and adjusting their price approach as necessary.\n",
    "\n",
    "Lead Generation: Web scraping is a technique for obtaining contact details from websites, such as email addresses and phone numbers, which can then be used for lead generation or marketing. This is especially helpful for companies looking"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What are the different methods used for Web Scraping?\n",
    "Ans. Web scraping can be done using a number of techniques, such as:\n",
    "\n",
    "Manual web scraping entails manually copying and pasting information from webpages into a database or spreadsheet. While time-consuming and impractical for large-scale scraping efforts, this technique can be helpful for quick, small-scale jobs.\n",
    "\n",
    "HTML parsing: To extract the pertinent information from a webpage's HTML code, programming languages like Python or JavaScript are used. Although it needs some coding experience, this technique has the potential to be quite effective.\n",
    "\n",
    "Utilising Web Scraping solutions: A variety of web scraping solutions are available to make the process of scraping websites easier. Software like Octoparse, ParseHub, and Beautiful Soup are examples of these resources. Typically, these technologies enable users to choose the data visually.\n",
    "\n",
    "Application Programming Interfaces (APIs): A few websites offer APIs that let programmers have structured access to their data. APIs, which are created particularly for this purpose, offer a more effective and dependable method of gaining access to data than web scraping.\n",
    "\n",
    "Headless Browsers: By imitating a user's interaction with a website, headless browsers like Puppeteer and Selenium can be used to automate web scraping operations. Although this technique is more difficult than others, it can be helpful for scraping dynamic websites that need user participation.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What is Beautiful Soup? Why is it used?\n",
    "Ans. A Python module called Beautiful Soup is employed for web scraping. It offers a straightforward method to parse HTML and XML files, enabling users to extract particular information from a webpage.\n",
    "\n",
    "Because it makes the process of obtaining data from HTML and XML documents simpler, Beautiful Soup is utilised for web scraping. It gives you access to a set of effective but simple tools for navigating and exploring the document's structure and finding the information you require.\n",
    "\n",
    "The following are some of Beautiful Soup's standout elements:\n",
    "\n",
    "Accessing elements and their attributes is made simple with the help of Beautiful Soup's interface for exploring an HTML/XML tree on a webpage.\n",
    "\n",
    "Finding the information you need is made simple by the ability to search for tags by name, attributes, or text content.\n",
    "\n",
    "Modifying the HTML/XML tree is possible with Beautiful Soup by adding, deleting, or changing tags and their associated attributes.\n",
    "\n",
    "Encoding detection: When working with non-ASCII characters, Beautiful Soup automatically determines the document's encoding.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Why is flask used in this Web Scraping project?\n",
    "Ans. Flask is a popular Python web framework that can be used to construct web apps as well as web scraping projects. Flask is a lightweight framework that is simple to install and use, making it an excellent choice for small to medium-sized web scraping projects.\n",
    "\n",
    "The following are some of the reasons why Flask might be utilised in a web scraping project:\n",
    "\n",
    "Creating a web interface: Flask can be used to create a basic web interface for a web scraping project. This enables users to engage with the project and view the scraped data in an intuitive manner.\n",
    "\n",
    "\n",
    "Flask can be used to run a web server, which is required for web scraping programmes that require data from the internet. The server can handle HTTP requests, answers, and serve scraped data.\n",
    "\n",
    "Flask can be integrated with other Python tools and packages that are often used in web scraping projects, such as Beautiful Soup and Requests. This makes it simple to construct."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "Ans. Elastic Beanstalk and Code pipeline is the AwS services that is used in above prject\n",
    "\n",
    "Elastic Beanstalk: Elastic Beanstalk is a fully-managed service provided by Amazon Web Services (AWS) that makes it simple to deploy and execute cloud applications. Python, Node.js, Java, and Ruby on Rails are among the programming languages and web frameworks supported.\n",
    "\n",
    "Developers can use Elastic Beanstalk to swiftly launch web apps without worrying about the underlying infrastructure. Based on the application's requirements, the service automatically provisioned resources such as compute instances, load balancers, and databases. Elastic Beanstalk also manages capacity provisioning, software updates, and monitoring, freeing developers to concentrate on developing their applications.\n",
    "\n",
    "Code Pipeline:AWS CodePipeline is a fully managed continuous delivery service that allows developers to automate application construction, testing, and deployment. It is a technology that helps to optimise the software release process and deliver features to end customers more quickly and reliably.\n",
    "\n",
    "Developers can use CodePipeline to create a pipeline that automatically builds, tests, and deploys code updates. Source code management, build, testing, and deployment are examples of pipeline steps. Each step can be customised to perform specific tasks such as running tests, creating Docker images, and deploying code to AWS services such as Elastic Beanstalk, Lambda, and EC2.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
