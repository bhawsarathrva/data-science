{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dca68f87",
   "metadata": {},
   "source": [
    "Q1. Describe the decision tree classifier algorithm and how it works to make predictions.\n",
    "\n",
    "Q2. Provide a step-by-step explanation of the mathematical intuition behind decision tree classification.\n",
    "\n",
    "Q3. Explain how a decision tree classifier can be used to solve a binary classification problem.\n",
    "\n",
    "Q4. Discuss the geometric intuition behind decision tree classification and how it can be used to make\n",
    "predictions.\n",
    "\n",
    "Q5. Define the confusion matrix and describe how it can be used to evaluate the performance of a\n",
    "classification model.\n",
    "\n",
    "Q6. Provide an example of a confusion matrix and explain how precision, recall, and F1 score can be\n",
    "calculated from it.\n",
    "\n",
    "Q7. Discuss the importance of choosing an appropriate evaluation metric for a classification problem and\n",
    "explain how this can be done.\n",
    "\n",
    "Q8. Provide an example of a classification problem where precision is the most important metric, and\n",
    "explain why.\n",
    "\n",
    "Q9. Provide an example of a classification problem where recall is the most important metric, and explain\n",
    "why"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daffb4e4",
   "metadata": {},
   "source": [
    "# Decision Tree Classification Assignment\n",
    "This notebook contains solutions to the questions related to Decision Tree classifiers and evaluation metrics, as outlined in the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a24e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd00e272",
   "metadata": {},
   "source": [
    "## Q1: Describe the Decision Tree Classifier Algorithm\n",
    "A Decision Tree is a supervised machine learning algorithm used for classification and regression tasks. It splits the dataset into subsets based on the most significant attribute at each node, creating a tree structure. Each leaf represents a decision outcome.\n",
    "\n",
    "### How it works:\n",
    "- Start with the entire dataset.\n",
    "- Calculate impurity measures (e.g., Gini Index, Entropy) for all features.\n",
    "- Split the dataset on the feature that minimizes impurity.\n",
    "- Repeat the process recursively on subsets until a stopping condition is met."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50a4d26",
   "metadata": {},
   "source": [
    "## Q2: Step-by-step Explanation of the Mathematical Intuition\n",
    "### Example of Gini Index Calculation:\n",
    "1. For a dataset with \\( N \\) samples and \\( K \\) classes:\n",
    "   \\[ Gini = 1 - \\sum_{i=1}^{K} (p_i)^2 \\]\n",
    "   where \\( p_i \\) is the proportion of samples belonging to class \\( i \\).\n",
    "2. Calculate the Gini index before splitting.\n",
    "3. For each split:\n",
    "   - Compute weighted Gini indices for subsets.\n",
    "   - Choose the split with the lowest weighted Gini index.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4944e2c",
   "metadata": {},
   "source": [
    "## Q3: Solving Binary Classification with Decision Trees\n",
    "A binary classification problem involves categorizing data points into one of two classes.\n",
    "For example, detecting spam emails (spam or not spam).\n",
    "\n",
    "Using a decision tree:\n",
    "- It learns rules such as 'If subject contains certain words, classify as spam'.\n",
    "- The model can handle both numerical and categorical features effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d8bfa9",
   "metadata": {},
   "source": [
    "## Q4: Geometric Intuition of Decision Trees\n",
    "Decision Trees partition the feature space into regions using axis-aligned splits. Each region corresponds to a class label.\n",
    "\n",
    "For example, in a 2D space:\n",
    "- A split at x=5 divides the plane into two halves.\n",
    "- Further splits create smaller regions, each assigned a label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3197c0d5",
   "metadata": {},
   "source": [
    "## Q5: Confusion Matrix Definition and Usage\n",
    "A confusion matrix is a table used to evaluate the performance of a classification model:\n",
    "\n",
    "| Actual \\ Predicted | Positive | Negative |\n",
    "|---------------------|----------|----------|\n",
    "| **Positive**        | TP       | FN       |\n",
    "| **Negative**        | FP       | TN       |\n",
    "\n",
    "- **TP**: True Positives\n",
    "- **FN**: False Negatives\n",
    "- **FP**: False Positives\n",
    "- **TN**: True Negatives\n",
    "\n",
    "It helps calculate metrics like accuracy, precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0cc4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Confusion Matrix and Metric Calculation\n",
    "\n",
    "# Simulated true labels and predictions\n",
    "y_true = [1, 1, 0, 1, 0, 0, 1, 0, 1, 0]\n",
    "y_pred = [1, 0, 0, 1, 0, 1, 1, 0, 1, 0]\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Metrics\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# Visualize Confusion Matrix\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd16cf7",
   "metadata": {},
   "source": [
    "## Q7: Choosing Appropriate Evaluation Metrics\n",
    "The choice of evaluation metric depends on the problem:\n",
    "- **Accuracy**: Suitable when class distribution is balanced.\n",
    "- **Precision**: Important when false positives are costly.\n",
    "- **Recall**: Crucial when missing positives is risky.\n",
    "- **F1 Score**: Best for imbalanced classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b2a57c",
   "metadata": {},
   "source": [
    "## Q8: Example of When Precision is Important\n",
    "Precision is important in spam detection because false positives (marking legitimate emails as spam) can cause significant inconvenience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e283cf",
   "metadata": {},
   "source": [
    "## Q9: Example of When Recall is Important\n",
    "Recall is important in medical diagnosis (e.g., detecting cancer) because missing a positive case (false negative) can have severe consequences."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
